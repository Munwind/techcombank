{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc491a3f",
   "metadata": {},
   "source": [
    "# ESG Data Augmentation v·ªõi Real Labels\n",
    "\n",
    "Notebook n√†y s·∫Ω th·ª±c hi·ªán:\n",
    "1. **ƒê·ªçc v√† ph√¢n t√≠ch d·ªØ li·ªáu ESG features** t·ª´ file `esg_features_with_tiers_labels.csv` \n",
    "2. **Augment d·ªØ li·ªáu** ƒë·ªÉ tƒÉng k√≠ch th∆∞·ªõc dataset b·∫±ng nhi·ªÅu ph∆∞∆°ng ph√°p\n",
    "3. **S·ª≠ d·ª•ng real E, S, G labels** thay v√¨ synthetic labels\n",
    "4. **X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho integer columns** v√† ratio columns\n",
    "5. **Output augmented dataset** v·ªõi real labels ƒë·ªÉ training\n",
    "\n",
    "**ƒê·∫∑c ƒëi·ªÉm dataset:**\n",
    "- C√≥ real labels: `e_score`, `s_score`, `g_score`\n",
    "- T·∫•t c·∫£ columns ƒë·ªÅu integer, ngo·∫°i tr·ª´ `esg_pos_ratio`, `esg_neg_ratio`\n",
    "- X√≥a `esg_tier`, gi·ªØ `esg_cluster`\n",
    "- Noise injection ph·∫£i maintain integer constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd3270a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427152a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Removed 'esg_tier' column as requested\n",
      "=== ESG FEATURES DATA v·ªõi REAL LABELS ===\n",
      "Dataset shape: (49, 63)\n",
      "Number of companies: 49\n",
      "\n",
      "Column categorization:\n",
      "   Integer columns: 56\n",
      "   Ratio columns: 2 ['esg_pos_ratio', 'esg_neg_ratio']\n",
      "   Label columns: 3 ['e_score', 's_score', 'g_score']\n",
      "   Metadata columns: 2 ['filename', 'esg_cluster']\n",
      "\n",
      "First 3 rows preview:\n",
      "          filename  total_esg_mentions  esg_pos_ratio  esg_neg_ratio  \\\n",
      "0  AR BBC 2023.txt                 355       0.814085       0.185915   \n",
      "1  AR BBC 2024.txt                 708       0.922316       0.077684   \n",
      "2  AR BID 2024.txt                 891       0.955129       0.044871   \n",
      "\n",
      "   esg_cluster  e_score  s_score  g_score  \n",
      "0            2     70.6     65.6     66.4  \n",
      "1            2     68.1     71.0     73.0  \n",
      "2            1     59.7     60.9     65.0  \n",
      "\n",
      "=== REAL ESG LABELS ANALYSIS ===\n",
      "e_score: Œº=77.3, œÉ=14.2, range=[35.0, 95.0]\n",
      "s_score: Œº=77.2, œÉ=13.2, range=[35.0, 88.0]\n",
      "g_score: Œº=80.3, œÉ=11.2, range=[57.2, 95.0]\n",
      "\n",
      "ESG Cluster distribution:\n",
      "esg_cluster\n",
      "0    23\n",
      "1     7\n",
      "2    13\n",
      "3     6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== DATA QUALITY CHECKS ===\n",
      "Missing values: 0\n",
      "\n",
      "Integer columns validation (sample):\n",
      "   pos_env_climate_action: ‚úÖ All integers\n",
      "   neg_env_climate_action: ‚úÖ All integers\n",
      "   pos_env_energy_transition: ‚úÖ All integers\n",
      "   neg_env_energy_transition: ‚úÖ All integers\n",
      "   pos_env_water_stewardship: ‚úÖ All integers\n",
      "\n",
      "Ratio columns validation:\n",
      "   esg_pos_ratio: range=[0.814, 1.000]\n",
      "   esg_neg_ratio: range=[0.000, 0.186]\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu ESG features v·ªõi real labels\n",
    "esg_data = pd.read_csv('esg_features_with_tiers_labels.csv')\n",
    "\n",
    "# X√≥a c·ªôt esg_tier nh∆∞ y√™u c·∫ßu\n",
    "if 'esg_tier' in esg_data.columns:\n",
    "    esg_data = esg_data.drop('esg_tier', axis=1)\n",
    "    print(\"‚úÖ Removed 'esg_tier' column as requested\")\n",
    "\n",
    "print(\"=== ESG FEATURES DATA v·ªõi REAL LABELS ===\")\n",
    "print(f\"Dataset shape: {esg_data.shape}\")\n",
    "print(f\"Number of companies: {len(esg_data)}\")\n",
    "\n",
    "# Identify column types for augmentation\n",
    "ratio_cols = ['esg_pos_ratio', 'esg_neg_ratio']\n",
    "label_cols = ['e_score', 's_score', 'g_score']\n",
    "metadata_cols = ['filename', 'esg_cluster']\n",
    "integer_cols = [col for col in esg_data.columns \n",
    "                if col not in ratio_cols + label_cols + metadata_cols]\n",
    "\n",
    "print(f\"\\nColumn categorization:\")\n",
    "print(f\"   Integer columns: {len(integer_cols)}\")\n",
    "print(f\"   Ratio columns: {len(ratio_cols)} {ratio_cols}\")\n",
    "print(f\"   Label columns: {len(label_cols)} {label_cols}\")\n",
    "print(f\"   Metadata columns: {len(metadata_cols)} {metadata_cols}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã m·ªôt v√†i rows ƒë·∫ßu\n",
    "print(f\"\\nFirst 3 rows preview:\")\n",
    "display_cols = ['filename', 'total_esg_mentions', 'esg_pos_ratio', 'esg_neg_ratio', 'esg_cluster', 'e_score', 's_score', 'g_score']\n",
    "print(esg_data[display_cols].head(3))\n",
    "\n",
    "# Ph√¢n t√≠ch real ESG labels\n",
    "print(f\"\\n=== REAL ESG LABELS ANALYSIS ===\")\n",
    "for label_col in label_cols:\n",
    "    scores = esg_data[label_col]\n",
    "    print(f\"{label_col}: Œº={scores.mean():.1f}, œÉ={scores.std():.1f}, range=[{scores.min():.1f}, {scores.max():.1f}]\")\n",
    "\n",
    "# ESG Cluster distribution\n",
    "print(f\"\\nESG Cluster distribution:\")\n",
    "print(esg_data['esg_cluster'].value_counts().sort_index())\n",
    "\n",
    "# Data quality checks\n",
    "print(f\"\\n=== DATA QUALITY CHECKS ===\")\n",
    "print(f\"Missing values: {esg_data.isnull().sum().sum()}\")\n",
    "\n",
    "# Check integer constraints\n",
    "print(f\"\\nInteger columns validation (sample):\")\n",
    "for col in integer_cols[:5]:  # Check first 5 as sample\n",
    "    is_integer = esg_data[col].apply(lambda x: x == int(x) if pd.notnull(x) else True).all()\n",
    "    print(f\"   {col}: {'‚úÖ' if is_integer else '‚ùå'} All integers\")\n",
    "\n",
    "print(f\"\\nRatio columns validation:\")\n",
    "for col in ratio_cols:\n",
    "    min_val, max_val = esg_data[col].min(), esg_data[col].max()\n",
    "    print(f\"   {col}: range=[{min_val:.3f}, {max_val:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20208a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Enhanced data augmentation functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation Functions cho ESG Features v·ªõi Real Labels\n",
    "def augment_esg_data_with_labels(df, methods=['noise', 'interpolation', 'scaling', 'synthetic'], \n",
    "                                samples_per_method=2, noise_factor=0.05):\n",
    "    \"\"\"\n",
    "    Augment ESG features data v·ªõi real labels:\n",
    "    \n",
    "    - Maintain integer constraints cho t·∫•t c·∫£ columns ngo·∫°i tr·ª´ ratio columns\n",
    "    - Preserve label relationships\n",
    "    - Handle different column types appropriately\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define column types\n",
    "    ratio_cols = ['esg_pos_ratio', 'esg_neg_ratio']\n",
    "    label_cols = ['e_score', 's_score', 'g_score'] \n",
    "    metadata_cols = ['filename', 'esg_cluster']\n",
    "    integer_cols = [col for col in df.columns \n",
    "                    if col not in ratio_cols + label_cols + metadata_cols]\n",
    "    \n",
    "    print(f\"üîß Augmentation setup:\")\n",
    "    print(f\"   Integer columns: {len(integer_cols)}\")\n",
    "    print(f\"   Ratio columns: {len(ratio_cols)}\")\n",
    "    print(f\"   Label columns: {len(label_cols)}\")\n",
    "    \n",
    "    augmented_data = []\n",
    "    \n",
    "    # Gi·ªØ l·∫°i d·ªØ li·ªáu g·ªëc\n",
    "    print(f\"üìä Original data: {len(df)} samples\")\n",
    "    for idx, row in df.iterrows():\n",
    "        augmented_data.append(row.to_dict())\n",
    "    \n",
    "    # Method 1: Noise Injection v·ªõi integer constraints\n",
    "    if 'noise' in methods:\n",
    "        print(f\"üîä Applying noise injection...\")\n",
    "        for i in range(samples_per_method):\n",
    "            for idx, row in df.iterrows():\n",
    "                new_row = row.copy()\n",
    "                \n",
    "                # Integer columns: add noise then round\n",
    "                for col in integer_cols:\n",
    "                    original_value = row[col]\n",
    "                    # T·∫°o noise nh·ªè cho integer columns\n",
    "                    std = noise_factor * (abs(original_value) + 0.1)\n",
    "                    noise = np.random.normal(0, std)\n",
    "                    new_value = max(0, original_value + noise)\n",
    "                    new_row[col] = int(round(new_value))  # Round to integer\n",
    "                \n",
    "                # Ratio columns: normal noise\n",
    "                for col in ratio_cols:\n",
    "                    original_value = row[col]\n",
    "                    std = noise_factor * 0.1  # Smaller noise for ratios\n",
    "                    noise = np.random.normal(0, std)\n",
    "                    new_value = np.clip(original_value + noise, 0, 1)  # Keep in [0,1]\n",
    "                    new_row[col] = new_value\n",
    "                \n",
    "                # Labels: small noise but reasonable ranges\n",
    "                for col in label_cols:\n",
    "                    original_value = row[col]\n",
    "                    std = noise_factor * 5  # Allow up to ¬±2.5 point change\n",
    "                    noise = np.random.normal(0, std)\n",
    "                    new_value = np.clip(original_value + noise, 0, 100)  # Keep in [0,100]\n",
    "                    new_row[col] = round(new_value, 1)\n",
    "                \n",
    "                # Metadata: keep original\n",
    "                new_row['filename'] = f\"{row['filename']}_noise_{i+1}\"\n",
    "                \n",
    "                augmented_data.append(new_row)\n",
    "    \n",
    "    # Method 2: Interpolation\n",
    "    if 'interpolation' in methods:\n",
    "        print(f\"üîÑ Applying interpolation...\")\n",
    "        for i in range(samples_per_method):\n",
    "            for idx in range(len(df)):\n",
    "                # Ch·ªçn 2 samples ng·∫´u nhi√™n t·ª´ c√πng cluster n·∫øu c√≥ th·ªÉ\n",
    "                cluster = df.iloc[idx]['esg_cluster']\n",
    "                same_cluster = df[df['esg_cluster'] == cluster]\n",
    "                \n",
    "                if len(same_cluster) > 1:\n",
    "                    pair = same_cluster.sample(2)\n",
    "                else:\n",
    "                    pair = df.sample(2)\n",
    "                \n",
    "                row1, row2 = pair.iloc[0], pair.iloc[1]\n",
    "                \n",
    "                # Interpolate v·ªõi weight ng·∫´u nhi√™n\n",
    "                alpha = np.random.uniform(0.3, 0.7)\n",
    "                new_row = {}\n",
    "                \n",
    "                # Integer columns: interpolate then round\n",
    "                for col in integer_cols:\n",
    "                    interpolated = alpha * row1[col] + (1 - alpha) * row2[col]\n",
    "                    new_row[col] = int(round(interpolated))\n",
    "                \n",
    "                # Ratio columns: normal interpolation\n",
    "                for col in ratio_cols:\n",
    "                    new_row[col] = alpha * row1[col] + (1 - alpha) * row2[col]\n",
    "                \n",
    "                # Labels: interpolate\n",
    "                for col in label_cols:\n",
    "                    interpolated = alpha * row1[col] + (1 - alpha) * row2[col]\n",
    "                    new_row[col] = round(interpolated, 1)\n",
    "                \n",
    "                # Metadata\n",
    "                new_row['filename'] = f\"{row1['filename']}_interp_{i+1}\"\n",
    "                new_row['esg_cluster'] = row1['esg_cluster']  # Keep from first sample\n",
    "                \n",
    "                augmented_data.append(new_row)\n",
    "    \n",
    "    # Method 3: Feature Scaling\n",
    "    if 'scaling' in methods:\n",
    "        print(f\"üìè Applying feature scaling...\")\n",
    "        for i in range(samples_per_method):\n",
    "            for idx, row in df.iterrows():\n",
    "                new_row = row.copy()\n",
    "                \n",
    "                # Scale random subset of integer features\n",
    "                features_to_scale = np.random.choice(integer_cols, \n",
    "                                                   size=max(1, len(integer_cols)//3), \n",
    "                                                   replace=False)\n",
    "                \n",
    "                for col in features_to_scale:\n",
    "                    scale_factor = np.random.uniform(0.8, 1.2)\n",
    "                    scaled_value = row[col] * scale_factor\n",
    "                    new_row[col] = int(round(max(0, scaled_value)))\n",
    "                \n",
    "                # Adjust ratios slightly\n",
    "                for col in ratio_cols:\n",
    "                    scale_factor = np.random.uniform(0.95, 1.05)\n",
    "                    scaled_value = row[col] * scale_factor\n",
    "                    new_row[col] = np.clip(scaled_value, 0, 1)\n",
    "                \n",
    "                # Labels: minor scaling\n",
    "                for col in label_cols:\n",
    "                    scale_factor = np.random.uniform(0.95, 1.05)\n",
    "                    scaled_value = row[col] * scale_factor\n",
    "                    new_row[col] = round(np.clip(scaled_value, 0, 100), 1)\n",
    "                \n",
    "                new_row['filename'] = f\"{row['filename']}_scale_{i+1}\"\n",
    "                \n",
    "                augmented_data.append(new_row)\n",
    "    \n",
    "    # Method 4: Synthetic Generation based on clusters\n",
    "    if 'synthetic' in methods:\n",
    "        print(f\"ü§ñ Applying synthetic generation...\")\n",
    "        for cluster in df['esg_cluster'].unique():\n",
    "            cluster_data = df[df['esg_cluster'] == cluster]\n",
    "            \n",
    "            for i in range(samples_per_method):\n",
    "                # Calculate cluster statistics\n",
    "                new_row = {}\n",
    "                \n",
    "                # Integer columns: sample from cluster distribution\n",
    "                for col in integer_cols:\n",
    "                    cluster_mean = cluster_data[col].mean()\n",
    "                    cluster_std = cluster_data[col].std()\n",
    "                    if cluster_std == 0:\n",
    "                        cluster_std = 0.1\n",
    "                    \n",
    "                    synthetic_value = np.random.normal(cluster_mean, cluster_std)\n",
    "                    new_row[col] = int(round(max(0, synthetic_value)))\n",
    "                \n",
    "                # Ratio columns: cluster-based generation\n",
    "                for col in ratio_cols:\n",
    "                    cluster_mean = cluster_data[col].mean()\n",
    "                    cluster_std = cluster_data[col].std()\n",
    "                    if cluster_std == 0:\n",
    "                        cluster_std = 0.01\n",
    "                    \n",
    "                    synthetic_value = np.random.normal(cluster_mean, cluster_std)\n",
    "                    new_row[col] = np.clip(synthetic_value, 0, 1)\n",
    "                \n",
    "                # Labels: cluster-based with some variation\n",
    "                for col in label_cols:\n",
    "                    cluster_mean = cluster_data[col].mean()\n",
    "                    cluster_std = cluster_data[col].std()\n",
    "                    if cluster_std == 0:\n",
    "                        cluster_std = 2.0\n",
    "                    \n",
    "                    synthetic_value = np.random.normal(cluster_mean, cluster_std)\n",
    "                    new_row[col] = round(np.clip(synthetic_value, 0, 100), 1)\n",
    "                \n",
    "                # Metadata\n",
    "                new_row['filename'] = f\"synthetic_cluster_{cluster}_{i+1}.txt\"\n",
    "                new_row['esg_cluster'] = cluster\n",
    "                \n",
    "                augmented_data.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(augmented_data)\n",
    "\n",
    "print(\"üõ†Ô∏è Enhanced data augmentation functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "024f1700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PERFORMING DATA AUGMENTATION v·ªõi REAL LABELS ===\n",
      "üîß Augmentation setup:\n",
      "   Integer columns: 56\n",
      "   Ratio columns: 2\n",
      "   Label columns: 3\n",
      "üìä Original data: 49 samples\n",
      "üîä Applying noise injection...\n",
      "üîÑ Applying interpolation...\n",
      "üìè Applying feature scaling...\n",
      "ü§ñ Applying synthetic generation...\n",
      "\n",
      "=== AUGMENTATION RESULTS ===\n",
      "Original dataset: (49, 63)\n",
      "Augmented dataset: (351, 63)\n",
      "Increase factor: 7.2x\n",
      "\n",
      "=== INTEGER CONSTRAINT VALIDATION ===\n",
      "Integer columns validation (sample):\n",
      "   pos_env_climate_action: ‚úÖ All integers\n",
      "   neg_env_climate_action: ‚úÖ All integers\n",
      "   pos_env_energy_transition: ‚úÖ All integers\n",
      "   neg_env_energy_transition: ‚úÖ All integers\n",
      "   pos_env_water_stewardship: ‚úÖ All integers\n",
      "\n",
      "=== QUALITY CHECK ===\n",
      "Original data statistics:\n",
      "      total_esg_mentions  esg_pos_ratio  total_pos_environmental  \\\n",
      "mean              403.02           0.93                    61.41   \n",
      "std               255.02           0.04                    29.08   \n",
      "min                 3.00           0.81                     0.00   \n",
      "max              1293.00           1.00                   133.00   \n",
      "\n",
      "      total_pos_social  total_pos_governance  \n",
      "mean             36.04                278.69  \n",
      "std              22.11                198.94  \n",
      "min               0.00                  3.00  \n",
      "max             135.00                975.00  \n",
      "\n",
      "Augmented data statistics:\n",
      "      total_esg_mentions  esg_pos_ratio  total_pos_environmental  \\\n",
      "mean              408.07           0.93                    62.03   \n",
      "std               242.79           0.04                    27.21   \n",
      "min                 2.00           0.80                     0.00   \n",
      "max              1317.00           1.00                   140.00   \n",
      "\n",
      "      total_pos_social  total_pos_governance  \n",
      "mean             36.78                281.71  \n",
      "std              20.82                190.89  \n",
      "min               0.00                  3.00  \n",
      "max             137.00               1061.00  \n",
      "\n",
      "=== STATISTICAL COMPARISON ===\n",
      "total_esg_mentions:\n",
      "  Mean difference: 1.3%\n",
      "  Std difference: 4.8%\n",
      "esg_pos_ratio:\n",
      "  Mean difference: 0.2%\n",
      "  Std difference: 2.5%\n",
      "total_pos_environmental:\n",
      "  Mean difference: 1.0%\n",
      "  Std difference: 6.4%\n",
      "total_pos_social:\n",
      "  Mean difference: 2.1%\n",
      "  Std difference: 5.8%\n",
      "total_pos_governance:\n",
      "  Mean difference: 1.1%\n",
      "  Std difference: 4.0%\n"
     ]
    }
   ],
   "source": [
    "# Th·ª±c hi·ªán Data Augmentation v·ªõi Real Labels\n",
    "print(\"=== PERFORMING DATA AUGMENTATION v·ªõi REAL LABELS ===\")\n",
    "\n",
    "# Augment data v·ªõi enhanced function\n",
    "augmented_esg_data = augment_esg_data_with_labels(\n",
    "    esg_data, \n",
    "    methods=['noise', 'interpolation', 'scaling', 'synthetic'],\n",
    "    samples_per_method=2,  # 2 samples per method per original sample\n",
    "    noise_factor=0.04  # Noise factor nh·ªè ƒë·ªÉ gi·ªØ t√≠nh ch·∫•t d·ªØ li·ªáu\n",
    ")\n",
    "\n",
    "print(f\"\\n=== AUGMENTATION RESULTS ===\")\n",
    "print(f\"Original dataset: {esg_data.shape}\")\n",
    "print(f\"Augmented dataset: {augmented_esg_data.shape}\")\n",
    "print(f\"Increase factor: {len(augmented_esg_data) / len(esg_data):.1f}x\")\n",
    "\n",
    "# Ki·ªÉm tra integer constraints\n",
    "print(f\"\\n=== INTEGER CONSTRAINT VALIDATION ===\")\n",
    "ratio_cols = ['esg_pos_ratio', 'esg_neg_ratio']\n",
    "label_cols = ['e_score', 's_score', 'g_score']\n",
    "metadata_cols = ['filename', 'esg_cluster']\n",
    "integer_cols = [col for col in augmented_esg_data.columns \n",
    "                if col not in ratio_cols + label_cols + metadata_cols]\n",
    "\n",
    "# Check first 5 integer columns\n",
    "print(\"Integer columns validation (sample):\")\n",
    "for col in integer_cols[:5]:\n",
    "    # Check if all values are integers\n",
    "    is_integer = augmented_esg_data[col].apply(lambda x: x == int(x) if pd.notnull(x) else True).all()\n",
    "    print(f\"   {col}: {'‚úÖ' if is_integer else '‚ùå'} All integers\")\n",
    "\n",
    "# Ki·ªÉm tra ch·∫•t l∆∞·ª£ng augmentation\n",
    "print(f\"\\n=== QUALITY CHECK ===\")\n",
    "key_features = ['total_esg_mentions', 'esg_pos_ratio', 'total_pos_environmental', \n",
    "                'total_pos_social', 'total_pos_governance']\n",
    "\n",
    "print(\"Original data statistics:\")\n",
    "orig_stats = esg_data[key_features].describe()\n",
    "print(orig_stats.loc[['mean', 'std', 'min', 'max']].round(2))\n",
    "\n",
    "print(\"\\nAugmented data statistics:\")\n",
    "aug_stats = augmented_esg_data[key_features].describe()\n",
    "print(aug_stats.loc[['mean', 'std', 'min', 'max']].round(2))\n",
    "\n",
    "# Ki·ªÉm tra s·ª± kh√°c bi·ªát v·ªÅ mean v√† std\n",
    "print(f\"\\n=== STATISTICAL COMPARISON ===\")\n",
    "for feature in key_features:\n",
    "    orig_mean, orig_std = esg_data[feature].mean(), esg_data[feature].std()\n",
    "    aug_mean, aug_std = augmented_esg_data[feature].mean(), augmented_esg_data[feature].std()\n",
    "    \n",
    "    mean_diff = abs(aug_mean - orig_mean) / orig_mean * 100\n",
    "    std_diff = abs(aug_std - orig_std) / orig_std * 100 if orig_std > 0 else 0\n",
    "    \n",
    "    print(f\"{feature}:\")\n",
    "    print(f\"  Mean difference: {mean_diff:.1f}%\")\n",
    "    print(f\"  Std difference: {std_diff:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d1f19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYZING REAL ESG LABELS ===\n",
      "‚úÖ Using real E, S, G labels from dataset!\n",
      "\n",
      "=== REAL ESG LABELS STATISTICS ===\n",
      "       e_score  s_score  g_score\n",
      "count   351.00   351.00   351.00\n",
      "mean     77.26    77.10    80.22\n",
      "std      13.81    12.85    11.18\n",
      "min      34.60    34.10    56.30\n",
      "25%      71.35    70.95    71.85\n",
      "50%      82.10    82.60    85.50\n",
      "75%      87.40    87.90    87.90\n",
      "max      98.40    92.40    99.30\n",
      "\n",
      "=== INTER-SCORE CORRELATIONS ===\n",
      "         e_score  s_score  g_score\n",
      "e_score    1.000    0.955    0.847\n",
      "s_score    0.955    1.000    0.815\n",
      "g_score    0.847    0.815    1.000\n",
      "\n",
      "=== LABEL DISTRIBUTION BY CLUSTER ===\n",
      "\n",
      "Cluster 0 (163 samples):\n",
      "   e_score: Œº=83.2, œÉ=9.8\n",
      "   s_score: Œº=84.1, œÉ=10.1\n",
      "   g_score: Œº=87.0, œÉ=2.0\n",
      "\n",
      "Cluster 1 (51 samples):\n",
      "   e_score: Œº=53.4, œÉ=4.0\n",
      "   s_score: Œº=56.3, œÉ=4.0\n",
      "   g_score: Œº=60.9, œÉ=3.0\n",
      "\n",
      "Cluster 2 (93 samples):\n",
      "   e_score: Œº=71.9, œÉ=1.9\n",
      "   s_score: Œº=71.2, œÉ=4.7\n",
      "   g_score: Œº=72.1, œÉ=2.5\n",
      "\n",
      "Cluster 3 (44 samples):\n",
      "   e_score: Œº=94.1, œÉ=1.8\n",
      "   s_score: Œº=87.9, œÉ=1.3\n",
      "   g_score: Œº=94.8, œÉ=1.4\n",
      "\n",
      "=== DATA QUALITY CHECKS ===\n",
      "e_score:\n",
      "   Range: [34.6, 98.4]\n",
      "   Missing values: 0\n",
      "   Outliers (>3œÉ): 4\n",
      "s_score:\n",
      "   Range: [34.1, 92.4]\n",
      "   Missing values: 0\n",
      "   Outliers (>3œÉ): 5\n",
      "g_score:\n",
      "   Range: [56.3, 99.3]\n",
      "   Missing values: 0\n",
      "   Outliers (>3œÉ): 0\n",
      "\n",
      "‚úÖ Real labels analysis completed!\n"
     ]
    }
   ],
   "source": [
    "# Ph√¢n t√≠ch Real ESG Labels\n",
    "print(\"=== ANALYZING REAL ESG LABELS ===\")\n",
    "print(\"‚úÖ Using real E, S, G labels from dataset!\")\n",
    "\n",
    "# Th·ªëng k√™ v·ªÅ real labels\n",
    "print(f\"\\n=== REAL ESG LABELS STATISTICS ===\")\n",
    "label_cols = ['e_score', 's_score', 'g_score']\n",
    "label_stats = augmented_esg_data[label_cols].describe()\n",
    "print(label_stats.round(2))\n",
    "\n",
    "# T√≠nh correlation gi·ªØa c√°c scores\n",
    "print(f\"\\n=== INTER-SCORE CORRELATIONS ===\")\n",
    "correlation_matrix = augmented_esg_data[label_cols].corr()\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Ph√¢n t√≠ch distribution theo clusters\n",
    "print(f\"\\n=== LABEL DISTRIBUTION BY CLUSTER ===\")\n",
    "for cluster in sorted(augmented_esg_data['esg_cluster'].unique()):\n",
    "    cluster_data = augmented_esg_data[augmented_esg_data['esg_cluster'] == cluster]\n",
    "    print(f\"\\nCluster {cluster} ({len(cluster_data)} samples):\")\n",
    "    for col in label_cols:\n",
    "        mean_score = cluster_data[col].mean()\n",
    "        std_score = cluster_data[col].std()\n",
    "        print(f\"   {col}: Œº={mean_score:.1f}, œÉ={std_score:.1f}\")\n",
    "\n",
    "# Check for any anomalies\n",
    "print(f\"\\n=== DATA QUALITY CHECKS ===\")\n",
    "for col in label_cols:\n",
    "    scores = augmented_esg_data[col]\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"   Range: [{scores.min():.1f}, {scores.max():.1f}]\")\n",
    "    print(f\"   Missing values: {scores.isnull().sum()}\")\n",
    "    print(f\"   Outliers (>3œÉ): {len(scores[abs(scores - scores.mean()) > 3*scores.std()])}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Real labels analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8372ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPARING DATA v·ªõi REAL LABELS ===\n",
      "üìä Features prepared:\n",
      "  Number of features: 58\n",
      "  Data shape: (351, 58)\n",
      "  Sample features: ['pos_env_climate_action', 'neg_env_climate_action', 'pos_env_energy_transition', 'neg_env_energy_transition', 'pos_env_water_stewardship', 'neg_env_water_stewardship', 'pos_env_biodiversity_nature', 'neg_env_biodiversity_nature']...\n",
      "\n",
      "üìà Real Target statistics:\n",
      "  e_score: Œº=77.3, œÉ=13.8, range=[34.6, 98.4]\n",
      "  s_score: Œº=77.1, œÉ=12.9, range=[34.1, 92.4]\n",
      "  g_score: Œº=80.2, œÉ=11.2, range=[56.3, 99.3]\n",
      "\n",
      "‚úÖ Data preparation v·ªõi real labels completed!\n",
      "\n",
      "üìä FINAL AUGMENTED DATASET v·ªõi REAL LABELS:\n",
      "   ‚Ä¢ Original dataset: 49 companies\n",
      "   ‚Ä¢ Augmented dataset: 351 samples (7.2x increase)\n",
      "   ‚Ä¢ Features: 58 columns\n",
      "   ‚Ä¢ Real labels: E, S, G scores\n"
     ]
    }
   ],
   "source": [
    "# Chu·∫©n b·ªã d·ªØ li·ªáu v·ªõi Real Labels\n",
    "print(\"=== PREPARING DATA v·ªõi REAL LABELS ===\")\n",
    "\n",
    "# X√°c ƒë·ªãnh features v√† targets v·ªõi real labels\n",
    "exclude_cols = ['filename', 'esg_cluster', 'e_score', 's_score', 'g_score']\n",
    "feature_cols = [col for col in augmented_esg_data.columns if col not in exclude_cols]\n",
    "X = augmented_esg_data[feature_cols]\n",
    "\n",
    "print(f\"üìä Features prepared:\")\n",
    "print(f\"  Number of features: {len(feature_cols)}\")\n",
    "print(f\"  Data shape: {X.shape}\")\n",
    "print(f\"  Sample features: {feature_cols[:8]}...\")\n",
    "\n",
    "print(f\"\\nüìà Real Target statistics:\")\n",
    "label_cols = ['e_score', 's_score', 'g_score']\n",
    "for label_col in label_cols:\n",
    "    scores = augmented_esg_data[label_col]\n",
    "    print(f\"  {label_col}: Œº={scores.mean():.1f}, œÉ={scores.std():.1f}, range=[{scores.min():.1f}, {scores.max():.1f}]\")\n",
    "\n",
    "print(f\"\\n‚úÖ Data preparation v·ªõi real labels completed!\")\n",
    "print(f\"\\nüìä FINAL AUGMENTED DATASET v·ªõi REAL LABELS:\")\n",
    "print(f\"   ‚Ä¢ Original dataset: {len(esg_data)} companies\")\n",
    "print(f\"   ‚Ä¢ Augmented dataset: {len(augmented_esg_data)} samples ({len(augmented_esg_data)/len(esg_data):.1f}x increase)\")\n",
    "print(f\"   ‚Ä¢ Features: {len(feature_cols)} columns\")\n",
    "print(f\"   ‚Ä¢ Real labels: E, S, G scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c66b1e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAVING AUGMENTED DATASET v·ªõi REAL LABELS ===\n",
      "‚úÖ Saved augmented dataset: augmented_esg_dataset_with_real_labels.csv\n",
      "   ‚Ä¢ Shape: (351, 63)\n",
      "   ‚Ä¢ Columns: ['filename', 'pos_env_climate_action', 'neg_env_climate_action', 'pos_env_energy_transition', 'neg_env_energy_transition', 'pos_env_water_stewardship', 'neg_env_water_stewardship', 'pos_env_biodiversity_nature', 'neg_env_biodiversity_nature', 'pos_env_pollution_prevention', 'neg_env_pollution_prevention', 'pos_env_circular_economy', 'neg_env_circular_economy', 'pos_env_sustainable_practices', 'neg_env_sustainable_practices', 'pos_social_diversity_inclusion', 'neg_social_diversity_inclusion', 'pos_social_workforce_development', 'neg_social_workforce_development', 'pos_social_health_safety', 'neg_social_health_safety', 'pos_social_human_rights', 'neg_social_human_rights', 'pos_social_community_engagement', 'neg_social_community_engagement', 'pos_social_customer_stakeholder', 'neg_social_customer_stakeholder', 'pos_social_financial_inclusion', 'neg_social_financial_inclusion', 'pos_gov_corporate_governance', 'neg_gov_corporate_governance', 'pos_gov_ethics_integrity', 'neg_gov_ethics_integrity', 'pos_gov_transparency_disclosure', 'neg_gov_transparency_disclosure', 'pos_gov_risk_management', 'neg_gov_risk_management', 'pos_gov_compliance_legal', 'neg_gov_compliance_legal', 'pos_gov_stakeholder_relations', 'neg_gov_stakeholder_relations', 'pos_gov_innovation_technology', 'neg_gov_innovation_technology', 'pos_gov_cybersecurity_data', 'neg_gov_cybersecurity_data', 'total_sentences', 'total_words', 'total_pos_environmental', 'total_neg_environmental', 'total_pos_social', 'total_neg_social', 'total_pos_governance', 'total_neg_governance', 'total_environmental_mentions', 'total_social_mentions', 'total_governance_mentions', 'total_esg_mentions', 'esg_pos_ratio', 'esg_neg_ratio', 'esg_cluster', 'e_score', 's_score', 'g_score']\n",
      "\n",
      "üìã Sample of augmented dataset v·ªõi real labels:\n",
      "          filename  total_esg_mentions  esg_pos_ratio  esg_cluster  e_score  \\\n",
      "0  AR BBC 2023.txt                 355       0.814085            2     70.6   \n",
      "1  AR BBC 2024.txt                 708       0.922316            2     68.1   \n",
      "2  AR BID 2024.txt                 891       0.955129            1     59.7   \n",
      "3  AR DPM 2023.txt                 587       0.971065            2     71.6   \n",
      "4  AR DPM 2024.txt                 852       0.910845            2     74.5   \n",
      "\n",
      "   s_score  g_score  \n",
      "0     65.6     66.4  \n",
      "1     71.0     73.0  \n",
      "2     60.9     65.0  \n",
      "3     75.0     75.0  \n",
      "4     73.1     71.8  \n",
      "\n",
      "üéâ DATASET AUGMENTATION v·ªõi REAL LABELS COMPLETED!\n",
      "üöÄ Ready for XGBoost training v·ªõi real E, S, G labels!\n",
      "\n",
      "üìä FINAL SUMMARY:\n",
      "   ‚Ä¢ Original dataset: 49 companies\n",
      "   ‚Ä¢ Augmented dataset: 351 samples (7.2x increase)\n",
      "   ‚Ä¢ Features: 58 feature columns\n",
      "   ‚Ä¢ Real labels: E (77.3¬±13.8), S (77.1¬±12.9), G (80.2¬±11.2)\n",
      "   ‚Ä¢ Integer constraints: Maintained for all non-ratio columns\n",
      "   ‚Ä¢ Output file: augmented_esg_dataset_with_real_labels.csv\n",
      "\n",
      "üîç VALIDATION SUMMARY:\n",
      "   ‚Ä¢ Integer columns: 56 (should all be integers)\n",
      "   ‚Ä¢ Ratio columns: 2 (float values in [0,1])\n",
      "   ‚Ä¢ Real labels: 3 (E, S, G scores)\n",
      "   ‚Ä¢ No esg_tier column: ‚úÖ\n",
      "   ‚Ä¢ esg_cluster preserved: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# Save Augmented Dataset v·ªõi Real Labels\n",
    "print(\"=== SAVING AUGMENTED DATASET v·ªõi REAL LABELS ===\")\n",
    "\n",
    "# Save the complete augmented dataset with real labels\n",
    "output_filename = 'augmented_esg_dataset_with_real_labels.csv'\n",
    "augmented_esg_data.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved augmented dataset: {output_filename}\")\n",
    "print(f\"   ‚Ä¢ Shape: {augmented_esg_data.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(augmented_esg_data.columns)}\")\n",
    "\n",
    "# Display sample of the final dataset\n",
    "print(f\"\\nüìã Sample of augmented dataset v·ªõi real labels:\")\n",
    "sample_cols = ['filename', 'total_esg_mentions', 'esg_pos_ratio', 'esg_cluster', 'e_score', 's_score', 'g_score']\n",
    "if all(col in augmented_esg_data.columns for col in sample_cols):\n",
    "    print(augmented_esg_data[sample_cols].head())\n",
    "\n",
    "print(f\"\\nüéâ DATASET AUGMENTATION v·ªõi REAL LABELS COMPLETED!\")\n",
    "print(f\"üöÄ Ready for XGBoost training v·ªõi real E, S, G labels!\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\nüìä FINAL SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Original dataset: {len(esg_data)} companies\")\n",
    "print(f\"   ‚Ä¢ Augmented dataset: {len(augmented_esg_data)} samples ({len(augmented_esg_data)/len(esg_data):.1f}x increase)\")\n",
    "print(f\"   ‚Ä¢ Features: {len([col for col in augmented_esg_data.columns if col not in ['filename', 'esg_cluster', 'e_score', 's_score', 'g_score']])} feature columns\")\n",
    "print(f\"   ‚Ä¢ Real labels: E ({augmented_esg_data['e_score'].mean():.1f}¬±{augmented_esg_data['e_score'].std():.1f}), S ({augmented_esg_data['s_score'].mean():.1f}¬±{augmented_esg_data['s_score'].std():.1f}), G ({augmented_esg_data['g_score'].mean():.1f}¬±{augmented_esg_data['g_score'].std():.1f})\")\n",
    "print(f\"   ‚Ä¢ Integer constraints: Maintained for all non-ratio columns\")\n",
    "print(f\"   ‚Ä¢ Output file: {output_filename}\")\n",
    "\n",
    "# Validation summary\n",
    "print(f\"\\nüîç VALIDATION SUMMARY:\")\n",
    "ratio_cols = ['esg_pos_ratio', 'esg_neg_ratio']\n",
    "label_cols = ['e_score', 's_score', 'g_score']\n",
    "metadata_cols = ['filename', 'esg_cluster']\n",
    "integer_cols = [col for col in augmented_esg_data.columns \n",
    "                if col not in ratio_cols + label_cols + metadata_cols]\n",
    "\n",
    "print(f\"   ‚Ä¢ Integer columns: {len(integer_cols)} (should all be integers)\")\n",
    "print(f\"   ‚Ä¢ Ratio columns: {len(ratio_cols)} (float values in [0,1])\")\n",
    "print(f\"   ‚Ä¢ Real labels: {len(label_cols)} (E, S, G scores)\")\n",
    "print(f\"   ‚Ä¢ No esg_tier column: {'‚úÖ' if 'esg_tier' not in augmented_esg_data.columns else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ esg_cluster preserved: {'‚úÖ' if 'esg_cluster' in augmented_esg_data.columns else '‚ùå'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
