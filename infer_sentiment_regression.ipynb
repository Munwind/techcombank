{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce1f12a",
   "metadata": {},
   "source": [
    "# ðŸš€ Vietnamese ESG Sentiment Regression Inference\n",
    "\n",
    "Notebook for inferring sentiment scores from Vietnamese ESG text using the trained model.\n",
    "\n",
    "**Author**: AI Assistant  \n",
    "**Date**: June 13, 2025  \n",
    "**Purpose**: Simple inference function for Vietnamese sentiment regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc598a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ IMPORT REQUIRED LIBRARIES\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ca14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastSentimentRegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight sentiment regression model using DistilBERT\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='distilbert-base-multilingual-cased', dropout_rate=0.3):\n",
    "        super(FastSentimentRegressor, self).__init__()\n",
    "        \n",
    "        # Load pre-trained model\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Regression head\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()  # Output between 0-1\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get transformer outputs\n",
    "        outputs = self.transformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        \n",
    "        # Apply dropout and regression head\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        score = self.regressor(pooled_output)\n",
    "        \n",
    "        return score.squeeze()  # Remove last dimension\n",
    "\n",
    "print(\"ðŸ—ï¸ Model architecture defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b688f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¥ LOAD TRAINED MODEL\n",
    "def load_sentiment_model(model_path='sentiment_regressor_complete.pth', device='cpu'):\n",
    "    \"\"\"\n",
    "    Load the trained sentiment regression model\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the saved model file\n",
    "        device (str): Device to run inference on ('cpu' or 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, tokenizer, device)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ“¥ Loading sentiment model from {model_path}...\")\n",
    "        \n",
    "        # Set device\n",
    "        device = torch.device(device)\n",
    "        \n",
    "        # Load model checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "        config = checkpoint['config']\n",
    "        \n",
    "        # Initialize model\n",
    "        model = FastSentimentRegressor(\n",
    "            model_name=config['model_name'],\n",
    "            dropout_rate=config['dropout_rate']\n",
    "        )\n",
    "        \n",
    "        # Load trained weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
    "        \n",
    "        print(f\"âœ… Model loaded successfully on {device}\")\n",
    "        print(f\"ðŸŽ¯ Model Performance: RÂ² = {config['metrics']['r2']:.3f}, MAE = {config['metrics']['mae']:.3f}\")\n",
    "        \n",
    "        return model, tokenizer, device\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading model: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Load the model\n",
    "model, tokenizer, device = load_sentiment_model()\n",
    "\n",
    "if model is not None:\n",
    "    print(\"ðŸŽ‰ Model ready for inference!\")\n",
    "else:\n",
    "    print(\"âŒ Failed to load model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49387af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ MAIN INFERENCE FUNCTION\n",
    "def infer_sentiment(vietnamese_sentence):\n",
    "    \"\"\"\n",
    "    ðŸš€ MAIN INFERENCE FUNCTION\n",
    "    \n",
    "    Predict sentiment score for a Vietnamese sentence\n",
    "    \n",
    "    Args:\n",
    "        vietnamese_sentence (str): Vietnamese text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        float: Sentiment score between 0.0 and 1.0\n",
    "               - 0.0-0.3: Negative sentiment (TiÃªu cá»±c)\n",
    "               - 0.3-0.7: Neutral sentiment (Trung tÃ­nh)\n",
    "               - 0.7-1.0: Positive sentiment (TÃ­ch cá»±c)\n",
    "               \n",
    "    Example:\n",
    "        >>> score = infer_sentiment(\"CÃ´ng ty Ä‘áº§u tÆ° vÃ o nÄƒng lÆ°á»£ng xanh\")\n",
    "        >>> print(f\"Sentiment score: {score:.3f}\")\n",
    "        Sentiment score: 0.825\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if not isinstance(vietnamese_sentence, str):\n",
    "        raise TypeError(\"Input must be a string\")\n",
    "    \n",
    "    if len(vietnamese_sentence.strip()) == 0:\n",
    "        raise ValueError(\"Input sentence cannot be empty\")\n",
    "    \n",
    "    # Check if model is loaded\n",
    "    if model is None or tokenizer is None:\n",
    "        raise RuntimeError(\"Model not loaded. Please run the model loading cell first.\")\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            # Tokenize the sentence\n",
    "            encoded = tokenizer(\n",
    "                vietnamese_sentence,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=128,\n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "            \n",
    "            # Get prediction\n",
    "            score = model(encoded['input_ids'], encoded['attention_mask'])\n",
    "            \n",
    "            # Return as Python float\n",
    "            return float(score.item())\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during inference: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"ðŸš€ Inference function defined!\")\n",
    "print(\"ðŸ“ Usage: score = infer_sentiment('Vietnamese sentence here')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a10b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ª TEST THE INFERENCE FUNCTION\n",
    "print(\"ðŸ§ª Testing inference function with Vietnamese ESG sentences...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"CÃ´ng ty Ä‘áº§u tÆ° máº¡nh vÃ o nÄƒng lÆ°á»£ng tÃ¡i táº¡o vÃ  cÃ´ng nghá»‡ xanh.\",\n",
    "    \"ChÃ­nh sÃ¡ch mÃ´i trÆ°á»ng cá»§a doanh nghiá»‡p thiáº¿u minh báº¡ch.\",\n",
    "    \"NhÃ¢n viÃªn Ä‘Æ°á»£c Ä‘Ã o táº¡o ká»¹ nÄƒng vÃ  thÄƒng tiáº¿n cÃ´ng báº±ng.\",\n",
    "    \"Vi pháº¡m nghiÃªm trá»ng cÃ¡c quy Ä‘á»‹nh vá» an toÃ n lao Ä‘á»™ng.\",\n",
    "    \"CÃ´ng ty cÃ³ trÃ¡ch nhiá»‡m xÃ£ há»™i cao vÃ  Ä‘Ã³ng gÃ³p cho cá»™ng Ä‘á»“ng.\"\n",
    "]\n",
    "\n",
    "print(f\"ðŸ“Š Analyzing {len(test_sentences)} Vietnamese sentences...\\n\")\n",
    "\n",
    "for i, sentence in enumerate(test_sentences, 1):\n",
    "    try:\n",
    "        # Get sentiment score\n",
    "        score = infer_sentiment(sentence)\n",
    "        \n",
    "        # Determine label\n",
    "        if score >= 0.7:\n",
    "            label = \"TÃ­ch cá»±c ðŸŸ¢\"\n",
    "        elif score <= 0.3:\n",
    "            label = \"TiÃªu cá»±c ðŸ”´\"\n",
    "        else:\n",
    "            label = \"Trung tÃ­nh ðŸŸ¡\"\n",
    "        \n",
    "        print(f\"{i}. Score: {score:.3f} ({label})\")\n",
    "        print(f\"   ðŸ“ {sentence}\")\n",
    "        print(f\"   ðŸ”¢ Type: {type(score)} (Python {type(score).__name__})\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{i}. âŒ Error: {e}\")\n",
    "        print(f\"   ðŸ“ {sentence}\")\n",
    "        print()\n",
    "\n",
    "print(\"âœ… Testing completed!\")\n",
    "print(\"ðŸŽ¯ The function returns a Python float value between 0.0 and 1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d351de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“‹ USAGE EXAMPLES\n",
    "print(\"ðŸ“‹ USAGE EXAMPLES\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Example 1: Simple usage\n",
    "print(\"1ï¸âƒ£ Simple Usage:\")\n",
    "sentence1 = \"CÃ´ng ty Ä‘áº§u tÆ° vÃ o nÄƒng lÆ°á»£ng xanh\"\n",
    "score1 = infer_sentiment(sentence1)\n",
    "print(f\"   Input: '{sentence1}'\")\n",
    "print(f\"   Output: {score1:.3f} (type: {type(score1)})\\n\")\n",
    "\n",
    "# Example 2: With interpretation\n",
    "print(\"2ï¸âƒ£ With Interpretation:\")\n",
    "sentence2 = \"CÃ´ng ty gÃ¢y Ã´ nhiá»…m mÃ´i trÆ°á»ng nghiÃªm trá»ng\"\n",
    "score2 = infer_sentiment(sentence2)\n",
    "interpretation = \"Positive\" if score2 > 0.7 else \"Negative\" if score2 < 0.3 else \"Neutral\"\n",
    "print(f\"   Input: '{sentence2}'\")\n",
    "print(f\"   Score: {score2:.3f}\")\n",
    "print(f\"   Interpretation: {interpretation}\\n\")\n",
    "\n",
    "# Example 3: Multiple sentences\n",
    "print(\"3ï¸âƒ£ Batch Processing:\")\n",
    "sentences = [\n",
    "    \"Doanh nghiá»‡p tuÃ¢n thá»§ cÃ¡c tiÃªu chuáº©n ESG\",\n",
    "    \"CÃ´ng ty cÃ³ nhiá»u vi pháº¡m vá» mÃ´i trÆ°á»ng\",\n",
    "    \"NhÃ¢n viÃªn Ä‘Æ°á»£c Ä‘á»‘i xá»­ cÃ´ng báº±ng\"\n",
    "]\n",
    "\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    score = infer_sentiment(sent)\n",
    "    print(f\"   {i}. {score:.3f} - {sent}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Ready to use for your Vietnamese ESG sentiment analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04522c0",
   "metadata": {},
   "source": [
    "## ðŸ“– Function Documentation\n",
    "\n",
    "### `infer_sentiment(vietnamese_sentence)`\n",
    "\n",
    "**Purpose**: Predict sentiment score for Vietnamese ESG text\n",
    "\n",
    "**Parameters**:\n",
    "- `vietnamese_sentence` (str): Vietnamese text to analyze\n",
    "\n",
    "**Returns**: \n",
    "- `float`: Sentiment score between 0.0 and 1.0\n",
    "\n",
    "**Score Interpretation**:\n",
    "- **0.0 - 0.3**: Negative sentiment (TiÃªu cá»±c)\n",
    "- **0.3 - 0.7**: Neutral sentiment (Trung tÃ­nh)  \n",
    "- **0.7 - 1.0**: Positive sentiment (TÃ­ch cá»±c)\n",
    "\n",
    "**Example Usage**:\n",
    "```python\n",
    "# Single sentence\n",
    "score = infer_sentiment(\"CÃ´ng ty Ä‘áº§u tÆ° vÃ o nÄƒng lÆ°á»£ng sáº¡ch\")\n",
    "print(f\"Score: {score:.3f}\")  # Output: Score: 0.825\n",
    "\n",
    "# With interpretation\n",
    "if score > 0.7:\n",
    "    print(\"Positive sentiment\")\n",
    "elif score < 0.3:\n",
    "    print(\"Negative sentiment\")\n",
    "else:\n",
    "    print(\"Neutral sentiment\")\n",
    "```\n",
    "\n",
    "**Model Information**:\n",
    "- Based on DistilBERT multilingual model\n",
    "- Trained on Vietnamese ESG text\n",
    "- Fast inference (~37ms per sentence)\n",
    "- Lightweight and production-ready"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
