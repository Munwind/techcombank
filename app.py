from flask import Flask, request, jsonify
import os
import re
import pandas as pd
import numpy as np
import sklearn
from pathlib import Path
import PyPDF2
import pdfplumber
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel, AutoConfig
import joblib
import warnings
from sklearn.preprocessing import StandardScaler
from transformers import AutoTokenizer, AutoModelForTokenClassification
from transformers import pipeline
import torch

# ===== PDF PROCESSING FUNCTIONS =====
def read_pdf_with_pdfplumber(file_path: str) -> str:
    """Read PDF using pdfplumber - better for complex layouts"""
    text = ""
    try:
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        print(f"Error reading {file_path} with pdfplumber: {e}")
    return text

def pdf_to_text(pdf_path: str) -> str:
    """Convert PDF to text"""
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    print(f'get pdf file {pdf_path}')
    text = read_pdf_with_pdfplumber(pdf_path)
    
    if not text.strip():
        raise ValueError("No text extracted from PDF")
    
    return text

esg_keywords = {
    'Environmental': {
        'climate_action': [
            # Climate & Carbon
            'khÃ­ háº­u', 'biáº¿n Ä‘á»•i khÃ­ háº­u', 'carbon', 'khÃ­ tháº£i', 'phÃ¡t tháº£i', 'giáº£m phÃ¡t tháº£i',
            'trung hÃ²a carbon', 'net zero', 'carbon footprint', 'tÃ¡c Ä‘á»™ng khÃ­ háº­u', 'thÃ­ch á»©ng khÃ­ háº­u',
            'cam káº¿t khÃ­ háº­u', 'má»¥c tiÃªu khÃ­ háº­u', 'káº¿ hoáº¡ch khÃ­ háº­u', 'chiáº¿n lÆ°á»£c khÃ­ háº­u',
            'climate change', 'greenhouse gas', 'GHG', 'carbon emission', 'carbon neutral',
            'carbon reduction', 'decarbonization', 'climate resilience', 'climate action',
            'climate strategy', 'climate commitment', 'emission reduction', 'low carbon'
        ],
        
        'energy_transition': [
            # Energy & Technology
            'nÄƒng lÆ°á»£ng tÃ¡i táº¡o', 'nÄƒng lÆ°á»£ng xanh', 'nÄƒng lÆ°á»£ng sáº¡ch', 'tiáº¿t kiá»‡m nÄƒng lÆ°á»£ng',
            'hiá»‡u quáº£ nÄƒng lÆ°á»£ng', 'chuyá»ƒn Ä‘á»•i nÄƒng lÆ°á»£ng', 'cÃ´ng nghá»‡ xanh', 'cÃ´ng nghá»‡ sáº¡ch',
            'Ä‘iá»‡n máº·t trá»i', 'Ä‘iá»‡n giÃ³', 'Ä‘iá»‡n biomass', 'Ä‘iá»‡n háº¡t nhÃ¢n', 'thá»§y Ä‘iá»‡n',
            'há»‡ thá»‘ng nÄƒng lÆ°á»£ng thÃ´ng minh', 'lÆ°á»›i Ä‘iá»‡n thÃ´ng minh', 'lÆ°u trá»¯ nÄƒng lÆ°á»£ng',
            'renewable energy', 'clean energy', 'green energy', 'energy efficiency',
            'energy transition', 'solar power', 'wind power', 'hydroelectric', 'biomass',
            'smart grid', 'energy storage', 'clean technology', 'green technology'
        ],
        
        'circular_economy': [
            # Waste & Circular Economy
            'kinh táº¿ tuáº§n hoÃ n', 'quáº£n lÃ½ cháº¥t tháº£i', 'tÃ¡i cháº¿', 'tÃ¡i sá»­ dá»¥ng', 'giáº£m thiá»ƒu cháº¥t tháº£i',
            'xá»­ lÃ½ cháº¥t tháº£i', 'phÃ¢n loáº¡i rÃ¡c', 'á»§ compost', 'biogas', 'zero waste',
            'giáº£m-tÃ¡i sá»­ dá»¥ng-tÃ¡i cháº¿', '3R', 'bao bÃ¬ sinh há»c', 'bao bÃ¬ tÃ¡i cháº¿', 'nhá»±a sinh há»c',
            'thiáº¿t káº¿ xanh', 'sáº£n pháº©m xanh', 'chu trÃ¬nh sá»‘ng sáº£n pháº©m', 'eco-design',
            'circular economy', 'waste management', 'recycling', 'upcycling', 'reuse',
            'waste reduction', 'zero waste', 'biodegradable', 'compostable',
            'life cycle assessment', 'LCA', 'sustainable design', 'green products'
        ],
        
        'water_stewardship': [
            # Water Management
            'quáº£n lÃ½ nÆ°á»›c', 'tiáº¿t kiá»‡m nÆ°á»›c', 'báº£o vá»‡ nguá»“n nÆ°á»›c', 'cháº¥t lÆ°á»£ng nÆ°á»›c',
            'xá»­ lÃ½ nÆ°á»›c tháº£i', 'tÃ¡i sá»­ dá»¥ng nÆ°á»›c', 'hiá»‡u quáº£ sá»­ dá»¥ng nÆ°á»›c', 'báº£o tá»“n nÆ°á»›c',
            'nguá»“n tÃ i nguyÃªn nÆ°á»›c', 'nÆ°á»›c sáº¡ch', 'an toÃ n nÆ°á»›c', 'thu gom nÆ°á»›c mÆ°a',
            'nÆ°á»›c ngáº§m', 'Ã´ nhiá»…m nÆ°á»›c', 'giÃ¡m sÃ¡t cháº¥t lÆ°á»£ng nÆ°á»›c', 'tiÃªu chuáº©n nÆ°á»›c',
            'water management', 'water conservation', 'water efficiency', 'water quality',
            'water treatment', 'water recycling', 'water stewardship', 'clean water',
            'water safety', 'water security', 'water footprint', 'sustainable water'
        ],
        
        'biodiversity_nature': [
            # Biodiversity & Ecosystem
            'Ä‘a dáº¡ng sinh há»c', 'báº£o vá»‡ mÃ´i trÆ°á»ng', 'báº£o tá»“n thiÃªn nhiÃªn', 'há»‡ sinh thÃ¡i',
            'mÃ´i trÆ°á»ng sá»‘ng', 'báº£o vá»‡ Ä‘á»™ng váº­t hoang dÃ£', 'báº£o vá»‡ thá»±c váº­t', 'rá»«ng bá»n vá»¯ng',
            'trá»“ng rá»«ng', 'phá»¥c há»“i rá»«ng', 'chá»‘ng phÃ¡ rá»«ng', 'khu báº£o tá»“n', 'vÆ°á»n quá»‘c gia',
            'báº£o vá»‡ san hÃ´', 'báº£o vá»‡ Ä‘áº¡i dÆ°Æ¡ng', 'phá»¥c há»“i há»‡ sinh thÃ¡i', 'dá»‹ch vá»¥ há»‡ sinh thÃ¡i',
            'biodiversity', 'ecosystem', 'conservation', 'wildlife protection', 'habitat',
            'sustainable forestry', 'deforestation', 'reforestation', 'marine conservation',
            'coral reef', 'ecosystem restoration', 'natural capital', 'ecosystem services'
        ],
        
        'sustainable_practices': [
            # Agriculture & Supply Chain
            'nÃ´ng nghiá»‡p bá»n vá»¯ng', 'canh tÃ¡c bá»n vá»¯ng', 'chÄƒn nuÃ´i bá»n vá»¯ng', 'nÃ´ng nghiá»‡p há»¯u cÆ¡',
            'chuá»—i cung á»©ng bá»n vá»¯ng', 'nguá»“n cung bá»n vá»¯ng', 'truy xuáº¥t nguá»“n gá»‘c',
            'thÆ°Æ¡ng máº¡i cÃ´ng báº±ng', 'cÃ´ng báº±ng trong thÆ°Æ¡ng máº¡i', 'chá»©ng nháº­n bá»n vá»¯ng',
            'tiÃªu chuáº©n mÃ´i trÆ°á»ng', 'quáº£n lÃ½ mÃ´i trÆ°á»ng', 'ISO 14001', 'EMAS',
            'sustainable agriculture', 'organic farming', 'sustainable sourcing',
            'supply chain sustainability', 'traceability', 'fair trade', 'certification',
            'environmental management', 'sustainable procurement', 'green supply chain'
        ],
        
        'pollution_prevention': [
            # Pollution & Contamination
            'Ã´ nhiá»…m khÃ´ng khÃ­', 'Ã´ nhiá»…m nÆ°á»›c', 'Ã´ nhiá»…m Ä‘áº¥t', 'cháº¥t Ä‘á»™c háº¡i',
            'kiá»ƒm soÃ¡t Ã´ nhiá»…m', 'giáº£m Ã´ nhiá»…m', 'phÃ²ng ngá»«a Ã´ nhiá»…m', 'lÃ m sáº¡ch mÃ´i trÆ°á»ng',
            'cháº¥t tháº£i nguy háº¡i', 'hÃ³a cháº¥t Ä‘á»™c', 'kim loáº¡i náº·ng', 'pesticide', 'phÃ¢n bÃ³n hÃ³a há»c',
            'tiáº¿ng á»“n', 'Ã´ nhiá»…m Ã¡nh sÃ¡ng', 'bá»©c xáº¡', 'vi nhá»±a', 'cháº¥t gÃ¢y ung thÆ°',
            'air pollution', 'water pollution', 'soil contamination', 'toxic substances',
            'pollution control', 'environmental remediation', 'hazardous waste',
            'chemical pollution', 'noise pollution', 'light pollution', 'microplastics'
        ]
    },
    
    'Social': {
        'workforce_development': [
            # Employee Relations & Development
            'phÃºc lá»£i nhÃ¢n viÃªn', 'quyá»n lá»£i nhÃ¢n viÃªn', 'chÄƒm sÃ³c nhÃ¢n viÃªn', 'phÃ¡t triá»ƒn nhÃ¢n viÃªn',
            'Ä‘Ã o táº¡o vÃ  phÃ¡t triá»ƒn', 'nÃ¢ng cao ká»¹ nÄƒng', 'há»c táº­p suá»‘t Ä‘á»i', 'chuyá»ƒn Ä‘á»•i sá»‘ nhÃ¢n sá»±',
            'cÃ¢n báº±ng cuá»™c sá»‘ng cÃ´ng viá»‡c', 'sá»©c khá»e tinh tháº§n', 'stress cÃ´ng viá»‡c', 'burnout',
            'mÃ´i trÆ°á»ng lÃ m viá»‡c tÃ­ch cá»±c', 'vÄƒn hÃ³a doanh nghiá»‡p', 'gáº¯n káº¿t nhÃ¢n viÃªn',
            'employee welfare', 'employee benefits', 'workforce development', 'skill development',
            'lifelong learning', 'digital transformation', 'work-life balance', 'mental health',
            'employee engagement', 'corporate culture', 'talent development', 'career growth'
        ],
        
        'health_safety': [
            # Occupational Health & Safety
            'an toÃ n lao Ä‘á»™ng', 'sá»©c khá»e nghá» nghiá»‡p', 'an toÃ n táº¡i nÆ¡i lÃ m viá»‡c',
            'phÃ²ng ngá»«a tai náº¡n', 'quáº£n lÃ½ rá»§i ro an toÃ n', 'thiáº¿t bá»‹ báº£o há»™', 'Ä‘Ã o táº¡o an toÃ n',
            'khÃ¡m sá»©c khá»e Ä‘á»‹nh ká»³', 'chÄƒm sÃ³c sá»©c khá»e', 'báº£o hiá»ƒm y táº¿', 'há»— trá»£ y táº¿',
            'sá»©c khá»e cá»™ng Ä‘á»“ng', 'an toÃ n thá»±c pháº©m', 'vá»‡ sinh cÃ´ng nghiá»‡p', 'ergonomics',
            'occupational safety', 'workplace safety', 'health and safety', 'accident prevention',
            'safety management', 'safety training', 'health insurance', 'healthcare',
            'public health', 'food safety', 'industrial hygiene', 'occupational health'
        ],
        
        'diversity_inclusion': [
            # Diversity, Equity & Inclusion
            'Ä‘a dáº¡ng vÃ  hÃ²a nháº­p', 'bÃ¬nh Ä‘áº³ng giá»›i', 'bÃ¬nh Ä‘áº³ng cÆ¡ há»™i', 'khÃ´ng phÃ¢n biá»‡t Ä‘á»‘i xá»­',
            'Ä‘a dáº¡ng vÄƒn hÃ³a', 'Ä‘a dáº¡ng tháº¿ há»‡', 'Ä‘a dáº¡ng sáº¯c tá»™c', 'Ä‘a dáº¡ng tÃ´n giÃ¡o',
            'hÃ²a nháº­p ngÆ°á»i khuyáº¿t táº­t', 'tiáº¿p cáº­n cho ngÆ°á»i khuyáº¿t táº­t', 'thiáº¿t káº¿ toÃ n diá»‡n',
            'lÃ£nh Ä‘áº¡o Ä‘a dáº¡ng', 'cÆ¡ há»™i thÄƒng tiáº¿n cÃ´ng báº±ng', 'lÆ°Æ¡ng bÃ¬nh Ä‘áº³ng', 'gender pay gap',
            'diversity and inclusion', 'gender equality', 'equal opportunity', 'non-discrimination',
            'cultural diversity', 'ethnic diversity', 'age diversity', 'disability inclusion',
            'inclusive design', 'diverse leadership', 'pay equity', 'unconscious bias'
        ],
        
        'community_engagement': [
            # Community Development & Social Impact
            'phÃ¡t triá»ƒn cá»™ng Ä‘á»“ng', 'Ä‘áº§u tÆ° vÃ o cá»™ng Ä‘á»“ng', 'tÃ¡c Ä‘á»™ng xÃ£ há»™i', 'trÃ¡ch nhiá»‡m xÃ£ há»™i',
            'hoáº¡t Ä‘á»™ng tá»« thiá»‡n', 'tÃ¬nh nguyá»‡n viÃªn', 'há»— trá»£ giÃ¡o dá»¥c', 'há»c bá»•ng',
            'xÃ³a Ä‘Ã³i giáº£m nghÃ¨o', 'phÃ¡t triá»ƒn kinh táº¿ Ä‘á»‹a phÆ°Æ¡ng', 'táº¡o viá»‡c lÃ m', 'doanh nghiá»‡p xÃ£ há»™i',
            'Ä‘á»‘i tÃ¡c cá»™ng Ä‘á»“ng', 'tham gia cá»™ng Ä‘á»“ng', 'láº¯ng nghe cá»™ng Ä‘á»“ng', 'pháº£n há»“i cá»™ng Ä‘á»“ng',
            'community development', 'social impact', 'community investment', 'social responsibility',
            'philanthropy', 'volunteering', 'education support', 'poverty alleviation',
            'local economic development', 'job creation', 'social enterprise', 'community partnership'
        ],
        
        'human_rights': [
            # Human Rights & Labor Standards
            'quyá»n con ngÆ°á»i', 'quyá»n cÆ¡ báº£n', 'quyá»n lao Ä‘á»™ng', 'tiÃªu chuáº©n lao Ä‘á»™ng',
            'tá»± do káº¿t há»™i', 'quyá»n thÆ°Æ¡ng lÆ°á»£ng táº­p thá»ƒ', 'khÃ´ng lao Ä‘á»™ng cÆ°á»¡ng bá»©c',
            'khÃ´ng lao Ä‘á»™ng tráº» em', 'tuá»•i lao Ä‘á»™ng tá»‘i thiá»ƒu', 'Ä‘iá»u kiá»‡n lÃ m viá»‡c nhÃ¢n Ä‘áº¡o',
            'tÃ´n trá»ng nhÃ¢n pháº©m', 'cÃ´ng báº±ng vÃ  bÃ¬nh Ä‘áº³ng', 'quyá»n riÃªng tÆ°', 'tá»± do ngÃ´n luáº­n',
            'human rights', 'fundamental rights', 'labor rights', 'labor standards',
            'freedom of association', 'collective bargaining', 'forced labor', 'child labor',
            'decent work', 'fair treatment', 'dignity', 'privacy rights', 'freedom of speech'
        ],
        
        'customer_stakeholder': [
            # Customer Relations & Stakeholder Engagement
            'tráº£i nghiá»‡m khÃ¡ch hÃ ng', 'hÃ i lÃ²ng khÃ¡ch hÃ ng', 'cháº¥t lÆ°á»£ng dá»‹ch vá»¥', 'dá»‹ch vá»¥ khÃ¡ch hÃ ng',
            'an toÃ n sáº£n pháº©m', 'cháº¥t lÆ°á»£ng sáº£n pháº©m', 'trÃ¡ch nhiá»‡m sáº£n pháº©m', 'báº£o vá»‡ ngÆ°á»i tiÃªu dÃ¹ng',
            'quyá»n khÃ¡ch hÃ ng', 'minh báº¡ch thÃ´ng tin sáº£n pháº©m', 'marketing cÃ³ trÃ¡ch nhiá»‡m',
            'tiáº¿p cáº­n cÃ´ng báº±ng', 'giÃ¡ cáº£ há»£p lÃ½', 'báº£o vá»‡ dá»¯ liá»‡u khÃ¡ch hÃ ng', 'quyá»n riÃªng tÆ°',
            'customer experience', 'customer satisfaction', 'service quality', 'product safety',
            'product quality', 'consumer protection', 'customer rights', 'responsible marketing',
            'fair access', 'fair pricing', 'data protection', 'privacy protection'
        ],
        
        'financial_inclusion': [
            # Financial Access & Inclusion
            'tÃ i chÃ­nh toÃ n diá»‡n', 'tiáº¿p cáº­n tÃ i chÃ­nh', 'bao trÃ¹m tÃ i chÃ­nh', 'dá»‹ch vá»¥ tÃ i chÃ­nh cÆ¡ báº£n',
            'giÃ¡o dá»¥c tÃ i chÃ­nh', 'hiá»ƒu biáº¿t tÃ i chÃ­nh', 'tÃ­n dá»¥ng vi mÃ´', 'cho vay cÃ³ trÃ¡ch nhiá»‡m',
            'ngÃ¢n hÃ ng sá»‘', 'thanh toÃ¡n sá»‘', 'fintech', 'cÃ´ng nghá»‡ tÃ i chÃ­nh', 'blockchain',
            'dá»‹ch vá»¥ tÃ i chÃ­nh xanh', 'Ä‘áº§u tÆ° cÃ³ tÃ¡c Ä‘á»™ng', 'tÃ i chÃ­nh bá»n vá»¯ng', 'ESG investing',
            'financial inclusion', 'financial access', 'financial literacy', 'microfinance',
            'responsible lending', 'digital banking', 'digital payments', 'fintech',
            'green finance', 'sustainable finance', 'impact investing', 'ESG investing'
        ]
    },
    
    'Governance': {
        'corporate_governance': [
            # Board & Management Structure
            'quáº£n trá»‹ cÃ´ng ty', 'há»™i Ä‘á»“ng quáº£n trá»‹', 'ban giÃ¡m Ä‘á»‘c', 'ban Ä‘iá»u hÃ nh',
            'cÆ¡ cáº¥u quáº£n trá»‹', 'thÃ nh viÃªn Ä‘á»™c láº­p', 'ban kiá»ƒm soÃ¡t', 'á»§y ban chuyÃªn mÃ´n',
            'á»§y ban kiá»ƒm toÃ¡n', 'á»§y ban nhÃ¢n sá»±', 'á»§y ban lÆ°Æ¡ng thÆ°á»Ÿng', 'á»§y ban rá»§i ro',
            'Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ quáº£n trá»‹', 'quy trÃ¬nh ra quyáº¿t Ä‘á»‹nh', 'phÃ¢n quyá»n vÃ  á»§y quyá»n',
            'corporate governance', 'board of directors', 'executive management', 'independent directors',
            'board committees', 'audit committee', 'governance structure', 'decision making',
            'board effectiveness', 'management oversight', 'corporate structure'
        ],
        
        'ethics_integrity': [
            # Business Ethics & Anti-Corruption
            'Ä‘áº¡o Ä‘á»©c kinh doanh', 'liÃªm chÃ­nh', 'minh báº¡ch', 'trung thá»±c', 'chÃ­nh trá»±c',
            'chá»‘ng tham nhÅ©ng', 'chá»‘ng há»‘i lá»™', 'xung Ä‘á»™t lá»£i Ã­ch', 'quy táº¯c á»©ng xá»­',
            'vÄƒn hÃ³a Ä‘áº¡o Ä‘á»©c', 'Ä‘Æ°á»ng dÃ¢y nÃ³ng Ä‘áº¡o Ä‘á»©c', 'tá»‘ giÃ¡c vi pháº¡m', 'whistleblowing',
            'quÃ  táº·ng vÃ  tiáº¿p khÃ¡ch', 'lá»£i Ã­ch cÃ¡ nhÃ¢n', 'giao dá»‹ch liÃªn quan', 'fair dealing',
            'business ethics', 'integrity', 'transparency', 'anti-corruption', 'anti-bribery',
            'conflict of interest', 'code of conduct', 'ethical culture', 'whistleblowing',
            'gift policy', 'related party transactions', 'fair dealing', 'honest business'
        ],
        
        'risk_management': [
            # Enterprise Risk Management
            'quáº£n lÃ½ rá»§i ro', 'quáº£n lÃ½ rá»§i ro doanh nghiá»‡p', 'Ä‘Ã¡nh giÃ¡ rá»§i ro', 'kiá»ƒm soÃ¡t rá»§i ro',
            'giáº£m thiá»ƒu rá»§i ro', 'chuyá»ƒn giao rá»§i ro', 'cháº¥p nháº­n rá»§i ro', 'trÃ¡nh rá»§i ro',
            'rá»§i ro chiáº¿n lÆ°á»£c', 'rá»§i ro váº­n hÃ nh', 'rá»§i ro tÃ i chÃ­nh', 'rá»§i ro tuÃ¢n thá»§',
            'rá»§i ro danh tiáº¿ng', 'rá»§i ro cÃ´ng nghá»‡', 'rá»§i ro máº¡ng', 'rá»§i ro khÃ­ háº­u',
            'risk management', 'enterprise risk management', 'risk assessment', 'risk control',
            'risk mitigation', 'strategic risk', 'operational risk', 'financial risk',
            'compliance risk', 'reputational risk', 'cyber risk', 'climate risk'
        ],
        
        'compliance_legal': [
            # Regulatory Compliance & Legal
            'tuÃ¢n thá»§ phÃ¡p luáº­t', 'tuÃ¢n thá»§ quy Ä‘á»‹nh', 'tuÃ¢n thá»§ luáº­t Ä‘á»‹nh', 'chÃ­nh sÃ¡ch tuÃ¢n thá»§',
            'kiá»ƒm tra tuÃ¢n thá»§', 'giÃ¡m sÃ¡t tuÃ¢n thá»§', 'bÃ¡o cÃ¡o tuÃ¢n thá»§', 'Ä‘áº£m báº£o tuÃ¢n thá»§',
            'yÃªu cáº§u phÃ¡p lÃ½', 'nghÄ©a vá»¥ phÃ¡p lÃ½', 'cháº¿ tÃ i', 'vi pháº¡m phÃ¡p luáº­t',
            'chá»©ng nháº­n', 'giáº¥y phÃ©p', 'Ä‘Äƒng kÃ½', 'phÃª duyá»‡t', 'kiá»ƒm Ä‘á»‹nh', 'kiá»ƒm tra',
            'legal compliance', 'regulatory compliance', 'compliance policy', 'compliance monitoring',
            'legal requirements', 'regulatory requirements', 'certification', 'licensing',
            'regulatory approval', 'audit', 'inspection', 'enforcement'
        ],
        
        'transparency_disclosure': [
            # Transparency & Reporting
            'minh báº¡ch thÃ´ng tin', 'cÃ´ng bá»‘ thÃ´ng tin', 'bÃ¡o cÃ¡o', 'cÃ´ng khai',
            'bÃ¡o cÃ¡o thÆ°á»ng niÃªn', 'bÃ¡o cÃ¡o bá»n vá»¯ng', 'bÃ¡o cÃ¡o ESG', 'bÃ¡o cÃ¡o tÃ i chÃ­nh',
            'thÃ´ng tin báº¯t buá»™c', 'thÃ´ng tin tá»± nguyá»‡n', 'tiÃªu chuáº©n bÃ¡o cÃ¡o', 'cháº¥t lÆ°á»£ng bÃ¡o cÃ¡o',
            'kiá»ƒm toÃ¡n Ä‘á»™c láº­p', 'xÃ¡c minh bÃªn thá»© ba', 'Ä‘áº£m báº£o cháº¥t lÆ°á»£ng', 'reliability',
            'transparency', 'disclosure', 'reporting', 'annual report', 'sustainability report',
            'ESG reporting', 'financial reporting', 'mandatory disclosure', 'voluntary disclosure',
            'reporting standards', 'independent audit', 'third party verification', 'assurance'
        ],
        
        'stakeholder_relations': [
            # Stakeholder Engagement & Communication
            'quan há»‡ bÃªn liÃªn quan', 'tÆ°Æ¡ng tÃ¡c bÃªn liÃªn quan', 'giao tiáº¿p bÃªn liÃªn quan',
            'quan há»‡ cá»• Ä‘Ã´ng', 'quan há»‡ nhÃ  Ä‘áº§u tÆ°', 'Ä‘á»‘i thoáº¡i vá»›i cá»• Ä‘Ã´ng', 'Ä‘áº¡i há»™i cá»• Ä‘Ã´ng',
            'láº¯ng nghe Ã½ kiáº¿n', 'thu tháº­p pháº£n há»“i', 'tham váº¥n', 'Ä‘á»‘i thoáº¡i', 'há»£p tÃ¡c',
            'xÃ¢y dá»±ng niá»m tin', 'uy tÃ­n', 'danh tiáº¿ng', 'thÆ°Æ¡ng hiá»‡u', 'hÃ¬nh áº£nh cÃ´ng ty',
            'stakeholder engagement', 'stakeholder relations', 'shareholder relations',
            'investor relations', 'stakeholder dialogue', 'feedback', 'consultation',
            'trust building', 'reputation', 'corporate image', 'brand reputation'
        ],
        
        'cybersecurity_data': [
            # Information Security & Data Protection
            'an ninh máº¡ng', 'báº£o máº­t thÃ´ng tin', 'an toÃ n thÃ´ng tin', 'báº£o vá»‡ dá»¯ liá»‡u',
            'quyá»n riÃªng tÆ°', 'báº£o máº­t dá»¯ liá»‡u cÃ¡ nhÃ¢n', 'GDPR', 'luáº­t báº£o vá»‡ dá»¯ liá»‡u',
            'kiá»ƒm soÃ¡t truy cáº­p', 'xÃ¡c thá»±c', 'á»§y quyá»n', 'mÃ£ hÃ³a', 'firewall',
            'sao lÆ°u dá»¯ liá»‡u', 'khÃ´i phá»¥c tháº£m há»a', 'liÃªn tá»¥c hoáº¡t Ä‘á»™ng', 'á»©ng phÃ³ sá»± cá»‘',
            'cybersecurity', 'information security', 'data protection', 'privacy',
            'data privacy', 'GDPR compliance', 'access control', 'authentication',
            'encryption', 'data backup', 'disaster recovery', 'business continuity'
        ],
        
        'innovation_technology': [
            # Digital Innovation & Technology Governance
            'Ä‘á»•i má»›i sÃ¡ng táº¡o', 'chuyá»ƒn Ä‘á»•i sá»‘', 'cÃ´ng nghá»‡ má»›i', 'cÃ´ng nghá»‡ sá»‘',
            'trÃ­ tuá»‡ nhÃ¢n táº¡o', 'AI', 'machine learning', 'big data', 'phÃ¢n tÃ­ch dá»¯ liá»‡u',
            'blockchain', 'IoT', 'cloud computing', 'tá»± Ä‘á»™ng hÃ³a', 'robotics',
            'quáº£n trá»‹ cÃ´ng nghá»‡', 'quáº£n trá»‹ dá»¯ liá»‡u', 'quáº£n trá»‹ AI', 'Ä‘áº¡o Ä‘á»©c AI',
            'innovation', 'digital transformation', 'emerging technology', 'artificial intelligence',
            'machine learning', 'big data', 'data analytics', 'blockchain', 'IoT',
            'technology governance', 'data governance', 'AI governance', 'AI ethics'
        ]
    }
}

# Mapping categories to main ESG pillars for easy classification
esg_category_mapping = {
    'Environmental': [
        'climate_action', 'energy_transition', 'circular_economy', 
        'water_stewardship', 'biodiversity_nature', 'sustainable_practices', 
        'pollution_prevention'
    ],
    'Social': [
        'workforce_development', 'health_safety', 'diversity_inclusion',
        'community_engagement', 'human_rights', 'customer_stakeholder',
        'financial_inclusion'
    ],
    'Governance': [
        'corporate_governance', 'ethics_integrity', 'risk_management',
        'compliance_legal', 'transparency_disclosure', 'stakeholder_relations',
        'cybersecurity_data', 'innovation_technology'
    ]
}

total_keywords = sum(len(keywords) for category in esg_keywords.values() 
                    for keywords in category.values())

all_esg_keywords = []
for category in esg_keywords.values():
    for subcategory_keywords in category.values():
        all_esg_keywords.extend(subcategory_keywords)

# Chuyá»ƒn táº¥t cáº£ tá»« khÃ³a thÃ nh lowercase Ä‘á»ƒ so sÃ¡nh
all_esg_keywords_lower = [keyword.lower() for keyword in all_esg_keywords]

# -----------------------------------------------------------------
# Analyze the Sentiment
#------------------------------------------------------------------

import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel, AutoConfig
import warnings
warnings.filterwarnings('ignore')

class FastSentimentRegressor(nn.Module):
    """
    Lightweight sentiment regression model using DistilBERT
    """
    def __init__(self, model_name='distilbert-base-multilingual-cased', dropout_rate=0.3):
        super(FastSentimentRegressor, self).__init__()
        
        # Load pre-trained model
        self.config = AutoConfig.from_pretrained(model_name)
        self.transformer = AutoModel.from_pretrained(model_name)
        
        # Regression head
        self.dropout = nn.Dropout(dropout_rate)
        self.regressor = nn.Sequential(
            nn.Linear(self.config.hidden_size, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(64, 1),
            nn.Sigmoid()  # Output between 0-1
        )
        
    def forward(self, input_ids, attention_mask):
        # Get transformer outputs
        outputs = self.transformer(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        
        # Use [CLS] token representation
        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token
        
        # Apply dropout and regression head
        pooled_output = self.dropout(pooled_output)
        score = self.regressor(pooled_output)
        
        return score.squeeze()  # Remove last dimension

def load_sentiment_model(model_path='sentiment_regressor_complete.pth', device='cpu'):
    """
    Load the trained sentiment regression model
    
    Args:
        model_path (str): Path to the saved model file
        device (str): Device to run inference on ('cpu' or 'cuda')
    
    Returns:
        tuple: (model, tokenizer, device)
    """
    try:
        print(f"ðŸ“¥ Loading sentiment model from {model_path}...")
        
        # Set device
        device = torch.device(device)
        
        # Load model checkpoint
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        config = checkpoint['config']
        
        # Initialize model
        model = FastSentimentRegressor(
            model_name=config['model_name'],
            dropout_rate=config['dropout_rate']
        )
        
        # Load trained weights
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        model.to(device)
        
        # Load tokenizer
        tokenizer = AutoTokenizer.from_pretrained(config['model_name'])
        
        return model, tokenizer, device
        
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        return None, None, None

# ðŸš€ MAIN INFERENCE FUNCTION
def infer_sentiment(vietnamese_sentence):
    # Validate input
    if not isinstance(vietnamese_sentence, str):
        raise TypeError("Input must be a string")
    
    if len(vietnamese_sentence.strip()) == 0:
        raise ValueError("Input sentence cannot be empty")
    
    # Check if model is loaded
    if model is None or tokenizer is None:
        raise RuntimeError("Model not loaded. Please run the model loading cell first.")
    
    try:
        with torch.no_grad():
            # Tokenize the sentence
            encoded = tokenizer(
                vietnamese_sentence,
                truncation=True,
                padding='max_length',
                max_length=128,
                return_tensors='pt'
            ).to(device)
            
            # Get prediction
            score = model(encoded['input_ids'], encoded['attention_mask'])
            
            # Return as Python float
            return float(score.item())
            
    except Exception as e:
        print(f"âŒ Error during inference: {e}")
        raise

print("ðŸš€ Inference function defined!")

# ==============================
# DATAFRAME CREATION WITH ALL FEATURES
# ==============================

def extract_organization_names(text):
    """Processes text with the NER pipeline and returns a list of organization names."""
    if len(text) > 512:
        text = text[:512]

    ner_results = ner_pipeline(text)
    organization_names = []
    for entity in ner_results:

        if "ORG" in entity['entity_group'].upper(): # Case-insensitive check
            organization_names.append(entity['word'])
    return organization_names

def process_esg_files_working(texts: str, filename: str):
    all_results = []
    features = {
        'filename': filename,
        
        # Environmental features
        'pos_env_climate_action': 0, 'neg_env_climate_action': 0,
        'pos_env_energy_transition': 0, 'neg_env_energy_transition': 0,
        'pos_env_water_stewardship': 0, 'neg_env_water_stewardship': 0,
        'pos_env_biodiversity_nature': 0, 'neg_env_biodiversity_nature': 0,
        'pos_env_pollution_prevention': 0, 'neg_env_pollution_prevention': 0,
        'pos_env_circular_economy': 0, 'neg_env_circular_economy': 0,
        'pos_env_sustainable_practices': 0, 'neg_env_sustainable_practices': 0,
        
        # Social features
        'pos_social_diversity_inclusion': 0, 'neg_social_diversity_inclusion': 0,
        'pos_social_workforce_development': 0, 'neg_social_workforce_development': 0,
        'pos_social_health_safety': 0, 'neg_social_health_safety': 0,
        'pos_social_human_rights': 0, 'neg_social_human_rights': 0,
        'pos_social_community_engagement': 0, 'neg_social_community_engagement': 0,
        'pos_social_customer_stakeholder': 0, 'neg_social_customer_stakeholder': 0,
        'pos_social_financial_inclusion': 0, 'neg_social_financial_inclusion': 0,
        
        # Governance features
        'pos_gov_corporate_governance': 0, 'neg_gov_corporate_governance': 0,
        'pos_gov_ethics_integrity': 0, 'neg_gov_ethics_integrity': 0,
        'pos_gov_transparency_disclosure': 0, 'neg_gov_transparency_disclosure': 0,
        'pos_gov_risk_management': 0, 'neg_gov_risk_management': 0,
        'pos_gov_compliance_legal': 0, 'neg_gov_compliance_legal': 0,
        'pos_gov_stakeholder_relations': 0, 'neg_gov_stakeholder_relations': 0,
        'pos_gov_innovation_technology': 0, 'neg_gov_innovation_technology': 0,
        'pos_gov_cybersecurity_data': 0, 'neg_gov_cybersecurity_data': 0,
    }
    
    try:
        sentences = re.split(r'[.!?]+', texts)
        features['total_sentences'] = len(sentences)
        features['total_words'] = len(texts.split())
        features['NER_pos'] = 0
        features['NER_neg'] = 0

        esg_sentences = []
        esg_count = 0
        pos_count = 0
        neg_count = 0
        
        for i, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if len(sentence) < 10:
                continue
            
            sentence_lower = sentence.lower()
            
            # Find ESG keywords
            found_keywords = []
            for keyword in all_esg_keywords_lower:
                if keyword in sentence_lower:
                    found_keywords.append(keyword)
            
            if found_keywords:
                esg_count += 1
                
                # Find categories and subcategories
                categories_found = set()
                subcategories_found = set()
                
                for category, subcategories in esg_keywords.items():
                    for subcategory, keywords in subcategories.items():
                        for keyword in keywords:
                            if keyword.lower() in sentence_lower:
                                categories_found.add(category)
                                subcategories_found.add(subcategory)
                
                if (len(sentence.split()) > 50):
                    sentence = ' '.join(sentence.split()[:50])
                # Sentiment analysis
                sentiment_score = infer_sentiment(sentence)
                sentiment_label = 'neutral'
                

                if sentiment_score >= 0.7:
                    sentiment_label = 'positive'
                elif sentiment_score < 0.5:
                    sentiment_label = 'negative'

                name_list = extract_organization_names(sentence)
                for name in name_list:
                    if name.lower() not in company_esg_dict:
                        continue
                    else:
                        point = company_esg_dict[name.lower()]
                        if point < 0:
                            features['NER_neg'] += abs(point)
                        else:
                            features['NER_pos'] += abs(point)

                confidence = sentiment_score if sentiment_label == 'positive' else (1 - sentiment_score)
                
                esg_sentence_data = {
                    'sentence_id': i,
                    'sentence': sentence,
                    'keywords_found': found_keywords,
                    'categories': list(categories_found),
                    'subcategories': list(subcategories_found),
                    'keyword_count': len(found_keywords),
                    'sentiment': sentiment_label,
                    'confidence': confidence
                }
                
                # Count features based on sentiment and subcategory
                if sentiment_label == 'positive':
                    pos_count += 1
                    for subcategory in subcategories_found:
                        # Map subcategory to feature name and increment
                        if subcategory == 'climate_action':
                            features['pos_env_climate_action'] += 1
                        elif subcategory == 'energy_transition':
                            features['pos_env_energy_transition'] += 1
                        elif subcategory == 'water_stewardship':
                            features['pos_env_water_stewardship'] += 1
                        elif subcategory == 'biodiversity_nature':
                            features['pos_env_biodiversity_nature'] += 1
                        elif subcategory == 'pollution_prevention':
                            features['pos_env_pollution_prevention'] += 1
                        elif subcategory == 'circular_economy':
                            features['pos_env_circular_economy'] += 1
                        elif subcategory == 'sustainable_practices':
                            features['pos_env_sustainable_practices'] += 1
                        elif subcategory == 'diversity_inclusion':
                            features['pos_social_diversity_inclusion'] += 1
                        elif subcategory == 'workforce_development':
                            features['pos_social_workforce_development'] += 1
                        elif subcategory == 'health_safety':
                            features['pos_social_health_safety'] += 1
                        elif subcategory == 'human_rights':
                            features['pos_social_human_rights'] += 1
                        elif subcategory == 'community_engagement':
                            features['pos_social_community_engagement'] += 1
                        elif subcategory == 'customer_stakeholder':
                            features['pos_social_customer_stakeholder'] += 1
                        elif subcategory == 'financial_inclusion':
                            features['pos_social_financial_inclusion'] += 1
                        elif subcategory == 'corporate_governance':
                            features['pos_gov_corporate_governance'] += 1
                        elif subcategory == 'ethics_integrity':
                            features['pos_gov_ethics_integrity'] += 1
                        elif subcategory == 'transparency_disclosure':
                            features['pos_gov_transparency_disclosure'] += 1
                        elif subcategory == 'risk_management':
                            features['pos_gov_risk_management'] += 1
                        elif subcategory == 'compliance_legal':
                            features['pos_gov_compliance_legal'] += 1
                        elif subcategory == 'stakeholder_relations':
                            features['pos_gov_stakeholder_relations'] += 1
                        elif subcategory == 'innovation_technology':
                            features['pos_gov_innovation_technology'] += 1
                        elif subcategory == 'cybersecurity_data':
                            features['pos_gov_cybersecurity_data'] += 1
                            
                elif sentiment_label == 'negative':
                    neg_count += 1
                    for subcategory in subcategories_found:
                        # Map subcategory to feature name and increment
                        if subcategory == 'climate_action':
                            features['neg_env_climate_action'] += 1
                        elif subcategory == 'energy_transition':
                            features['neg_env_energy_transition'] += 1
                        elif subcategory == 'water_stewardship':
                            features['neg_env_water_stewardship'] += 1
                        elif subcategory == 'biodiversity_nature':
                            features['neg_env_biodiversity_nature'] += 1
                        elif subcategory == 'pollution_prevention':
                            features['neg_env_pollution_prevention'] += 1
                        elif subcategory == 'circular_economy':
                            features['neg_env_circular_economy'] += 1
                        elif subcategory == 'sustainable_practices':
                            features['neg_env_sustainable_practices'] += 1
                        elif subcategory == 'diversity_inclusion':
                            features['neg_social_diversity_inclusion'] += 1
                        elif subcategory == 'workforce_development':
                            features['neg_social_workforce_development'] += 1
                        elif subcategory == 'health_safety':
                            features['neg_social_health_safety'] += 1
                        elif subcategory == 'human_rights':
                            features['neg_social_human_rights'] += 1
                        elif subcategory == 'community_engagement':
                            features['neg_social_community_engagement'] += 1
                        elif subcategory == 'customer_stakeholder':
                            features['neg_social_customer_stakeholder'] += 1
                        elif subcategory == 'financial_inclusion':
                            features['neg_social_financial_inclusion'] += 1
                        elif subcategory == 'corporate_governance':
                            features['neg_gov_corporate_governance'] += 1
                        elif subcategory == 'ethics_integrity':
                            features['neg_gov_ethics_integrity'] += 1
                        elif subcategory == 'transparency_disclosure':
                            features['neg_gov_transparency_disclosure'] += 1
                        elif subcategory == 'risk_management':
                            features['neg_gov_risk_management'] += 1
                        elif subcategory == 'compliance_legal':
                            features['neg_gov_compliance_legal'] += 1
                        elif subcategory == 'stakeholder_relations':
                            features['neg_gov_stakeholder_relations'] += 1
                        elif subcategory == 'innovation_technology':
                            features['neg_gov_innovation_technology'] += 1
                        elif subcategory == 'cybersecurity_data':
                            features['neg_gov_cybersecurity_data'] += 1
                
                esg_sentences.append(esg_sentence_data)
        
        # Calculate aggregated features
        env_pos = sum([features[f'pos_env_{sub}'] for sub in ['climate_action', 'energy_transition', 'water_stewardship', 'biodiversity_nature', 'pollution_prevention', 'circular_economy', 'sustainable_practices']])
        env_neg = sum([features[f'neg_env_{sub}'] for sub in ['climate_action', 'energy_transition', 'water_stewardship', 'biodiversity_nature', 'pollution_prevention', 'circular_economy', 'sustainable_practices']])
        social_pos = sum([features[f'pos_social_{sub}'] for sub in ['diversity_inclusion', 'workforce_development', 'health_safety', 'human_rights', 'community_engagement', 'customer_stakeholder', 'financial_inclusion']])
        social_neg = sum([features[f'neg_social_{sub}'] for sub in ['diversity_inclusion', 'workforce_development', 'health_safety', 'human_rights', 'community_engagement', 'customer_stakeholder', 'financial_inclusion']])
        gov_pos = sum([features[f'pos_gov_{sub}'] for sub in ['corporate_governance', 'ethics_integrity', 'transparency_disclosure', 'risk_management', 'compliance_legal', 'stakeholder_relations', 'innovation_technology', 'cybersecurity_data']])
        gov_neg = sum([features[f'neg_gov_{sub}'] for sub in ['corporate_governance', 'ethics_integrity', 'transparency_disclosure', 'risk_management', 'compliance_legal', 'stakeholder_relations', 'innovation_technology', 'cybersecurity_data']])
        
        # Add aggregated features
        features.update({
            'total_pos_environmental': env_pos,
            'total_neg_environmental': env_neg,
            'total_pos_social': social_pos,
            'total_neg_social': social_neg,
            'total_pos_governance': gov_pos,
            'total_neg_governance': gov_neg,
            'total_environmental_mentions': env_pos + env_neg,
            'total_social_mentions': social_pos + social_neg,
            'total_governance_mentions': gov_pos + gov_neg,
            'total_esg_mentions': env_pos + env_neg + social_pos + social_neg + gov_pos + gov_neg,
            'esg_pos_ratio': (env_pos + social_pos + gov_pos) / max(env_pos + env_neg + social_pos + social_neg + gov_pos + gov_neg, 1),
            'esg_neg_ratio': (env_neg + social_neg + gov_neg) / max(env_pos + env_neg + social_pos + social_neg + gov_pos + gov_neg, 1),
        })
        
        all_results.append(features)
        
    except Exception as e:
        print(f"  âŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()

    # Create final dataframe
    df_all_files = pd.DataFrame(all_results) if all_results else None
    
    if df_all_files is not None:
        print(f"\\nðŸ“Š THÃ€NH CÃ”NG!")
    
    return df_all_files

def assign_cluster(df_new, feature_cols, cluster_centroids, scaler):
    df_new_scaled = scaler.transform(df_new[feature_cols])
    
    min_dist = float('inf')
    assigned_cluster = None
    
    for cluster, centroid in cluster_centroids.items():
        centroid_scaled = scaler.transform(centroid.values.reshape(1, -1))
        
        dist = np.linalg.norm(df_new_scaled - centroid_scaled)
        
        if dist < min_dist:
            min_dist = dist
            assigned_cluster = cluster
    
    return assigned_cluster

def infer_esg_scores(df, model_path='d:/Jupyter/hackathon_techcombank/'):
    """
    Inference function to predict E, S, G scores from input dataframe
    
    Args:
        df: pandas DataFrame with features (without labels)
        model_path: Path to the saved models directory
    
    Returns:
        pandas DataFrame with columns ['e_score', 's_score', 'g_score']
    """
    import pandas as pd
    import numpy as np
    import joblib
    import xgboost as xgb
    
    print("=== ESG SCORE INFERENCE ===")
    print(f"Input data shape: {df.shape}")
    
    # Load saved models and preprocessing objects
    try:
        e_model = joblib.load(f'{model_path}xgboost_e_score_model.pkl')
        s_model = joblib.load(f'{model_path}xgboost_s_score_model.pkl')
        g_model = joblib.load(f'{model_path}xgboost_g_score_model.pkl')
        scaler = joblib.load(f'{model_path}xgboost_scaler.pkl')
        label_encoders = joblib.load(f'{model_path}xgboost_encoders.pkl')
        feature_names = joblib.load(f'{model_path}xgboost_features.pkl')
        
        print("Models loaded successfully!")
        
    except FileNotFoundError as e:
        print(f"Error loading models: {e}")
        print("Please run train_esg_models() first to train and save the models.")
        return None
    
    # Prepare input data
    X = df.copy()
    
    # Remove non-feature columns if they exist
    exclude_cols = ['company_name', 'symbol', 'e_score', 's_score', 'g_score']
    for col in exclude_cols:
        if col in X.columns:
            X = X.drop(columns=[col])
    
    # Handle categorical variables using saved encoders
    for col, encoder in label_encoders.items():
        if col in X.columns:
            try:
                X[col] = encoder.transform(X[col].astype(str))
            except ValueError:
                # Handle unseen categories by assigning a default value
                print(f"Warning: Unseen categories in column '{col}', using most frequent class")
                X[col] = X[col].astype(str)
                # Replace unseen categories with the most frequent category from training
                known_classes = set(encoder.classes_)
                X[col] = X[col].apply(lambda x: x if x in known_classes else encoder.classes_[0])
                X[col] = encoder.transform(X[col])
    
    # Ensure we have all required features
    missing_features = set(feature_names) - set(X.columns)
    if missing_features:
        print(f"Warning: Missing features: {missing_features}")
        # Add missing features with default values (median or 0)
        for feature in missing_features:
            X[feature] = 0
    
    # Select and reorder features to match training
    X = X[feature_names]
    
    # Handle missing values (fill with median of available data)
    X = X.fillna(X.median())
    
    # If still any missing values, fill with 0
    X = X.fillna(0)
    
    print(f"Processed features shape: {X.shape}")
    
    # Scale features
    X_scaled = scaler.transform(X)
    
    # Make predictions
    e_scores = e_model.predict(X_scaled)
    s_scores = s_model.predict(X_scaled)
    g_scores = g_model.predict(X_scaled)
    
    # Create results dataframe
    results_df = pd.DataFrame({
        'e_score': e_scores,
        's_score': s_scores,
        'g_score': g_scores
    })
    
    print("=== INFERENCE COMPLETED ===")
    print(f"Predicted scores shape: {results_df.shape}")
    
    return results_df

if __name__ == "__main__":
    stored_text = pdf_to_text('D:/Jupyter/hackathon_techcombank/esg_report_pdf/AR SAB 2023.pdf')
    
    model, tokenizer, device = load_sentiment_model()
    model_name = "NlpHUST/ner-vietnamese-electra-base" 

    print(f"Loading tokenizer and model: {model_name}...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model_ner = AutoModelForTokenClassification.from_pretrained(model_name)

    ner_pipeline = pipeline("ner", model=model_ner, tokenizer=tokenizer, device='cpu', grouped_entities=True)

    df = pd.read_csv('company_esg.csv')

    import re

    def clean_company_name(name):
        prefixes = ['CÃ´ng ty CP', 'CÃ´ng ty Cá»• pháº§n', 'CÃ´ng ty TNHH', 'Táº­p Ä‘oÃ n', 'NgÃ¢n hÃ ng TMCP', 'NgÃ¢n hÃ ng', 'CÃ´ng ty']
        prefixes.sort(key=len, reverse=True)
        for prefix in prefixes:
            if name.startswith(prefix):
                name = name[len(prefix):].strip()
                break # Remove only one prefix
        return name

    df['company_name'] = df['company_name'].apply(clean_company_name)

    company_esg_dict = {}
    for index, row in df.iterrows():
        company_esg_dict[row['company_name'].lower()] = row[' esg_score'] - 2.5

    df_all_files = process_esg_files_working(stored_text, 'filename')

    df_train = pd.read_csv('esg_features_with_ner_scores.csv')

    feature_cols = [col for col in df_train.columns if col not in 
                ['filename', 'esg_tier', 'esg_cluster', 'e_score', 's_score', 'g_score']]

    cluster_centroids = {}
    for cluster in df_train['esg_cluster'].unique():
        cluster_data = df_train[df_train['esg_cluster'] == cluster]
        cluster_centroids[cluster] = cluster_data[feature_cols].mean()

    scaler = StandardScaler()
    scaler.fit(df_train[feature_cols])

    assigned_cluster = assign_cluster(df_all_files, feature_cols, cluster_centroids, scaler)

    df_all_files['esg_cluster'] = assigned_cluster

    # this has the output of 20 features
    df_all_files.to_csv('esg_features_bbc_2023.csv', index=False)

    inferred_scores = infer_esg_scores(df_all_files, model_path='d:/Jupyter/hackathon_techcombank/')

    print(inferred_scores) # This is the return score (E, S, G)

